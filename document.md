# Project Experiences

## ScummVM (GSoC Project)

ScummVM的目的是修复那些在已经不被现代操作系统所兼容的游戏引擎。我们根据文档和已有的代码，重新实现那些引擎，并让他们可以重新在现代的操作系统中加载并运行他们所支持的游戏。

ScummVM本质上是一个虚拟机（VM），他兼容目前的大多数操作系统并在此之上构建对应的API，然后根据抽象出来的API去复现曾经的引擎，测试并发布游戏。

我的任务是修复引擎Director，他是Flash Player的前身。我负责修复Director的渲染部分，同时测试游戏的完整性，并在发现缺陷的时候修复对应的地方。

起初上手的时候由于项目规模较大，很多地方我都不能很好的去掌握，所以害怕出现修复了一处bug又出现两处的情况。在经过了大概两个月的熟悉已经开发feature后，我的mentor给了我直接向仓库提交的权限，之后我就可以自己把握项目的进度以及对引擎有一个整体的了解了，所以后面的过程还是比较轻松的。

项目是用C++写的，在开发的过程中设计到一部分汇编的东西，有的时候我需要去查阅老式的macintosh的设计细节，才能知道我要去怎么复现对应的模块。ScummVM整体有300万行代码，但是在我负责的Director引擎中，只有5万行左右。社区中的同伴开发了一个可以自动化测试的工具，每次我们尝试提交他都会自动测试新版本的代码会不会破坏对以前游戏的支持。让我们可以快速发现代码中的潜在bug并修复

最终结束的时候我成功修复了两款游戏并发布，当时一经发布我们的IRC中就来了很多人来询问或者希望提供支持。有的人带来了很多曾经这个引擎支持但是我们无法获得到的游戏。还有的人表示希望参与一同的开发。所以当时看到这个情况的时候我是相当自豪的，因为我修复的游戏让这个引擎又焕发了生机。

我的GSoC项目的总结可以在这里找到，[链接](https://blogs.scummvm.org/sheep/2021/08/21/beginging-or-the-ending-gsoc-summary/)

## TinyOS

TinyOS是用Rust重写了xv6。xv6是mit6.s081课程中的教学操作系统，是对unix第6版的一个重实现。由于我在学习完mit6.s081以后，感觉自己对操作系统这个整体还没有一个很好的认识，并且恰好那段时间对Rust比较感兴趣正在学习，所以用Rust将xv6重写了一遍，以此来强化自己对操作系统的理解。

目前TinyOS对于系统调用的支持还不是很完备，但是内核内部的东西已经实现完全了。包括进程的调度，文件系统，内存管理，中断处理等。目前可以执行一些简单的系统调用，比如用户层级的`echo hi`

我是独立完成这个project的，在实现的过程中，有一个比较有意思的点卡了我比较长的时间。因为xv6内部对于每个进程的用户栈和内核栈都只分配了一页的内存空间。在C语言编写的xv6中，是没问题的。但是我在用rust重写的时候，由于panic宏的展开导致一个函数内部耗费的空间会比较大，所以有的时候一个页的栈是不够用的。同时恰好在内核内部处理中断的时候，我们会把参数暂存到内核栈中，然后进入中断处理程序。但是如果这时候我们访问到了没有分配到的页，那么他就会再次启动中断的流程。导致最后出现各种奇怪的现象。虽然本身只是由于内核栈空间不够导致的，但是最后显现给我们的现象却是完全不同的。

代码可以在我的github中找到，[链接](https://github.com/ysj1173886760/TinyOS)

## ShardKV

ShardKV是mit6.824的project，是用基于Raft的服务器实现一个分片的键值服务器。总体的思路就是multi-raft。每一个Raft Group负责管理若干个分片。当用户请求数据的时候会首先向ShardCtrler请求当前的配置，并根据我们要请求的数据对应的分片找到对应的Raft组，然后再向Raft组去请求服务。

整个project有两个难点，一个是正确的实现Raft，我们要考虑到各种的细节问题，并实现一个Raft的底层服务。为之后在Raft之上构建KV服务器做准备。第二个就是multi-raft，由于Shard是可以改变位置的，比如从一个group迁移到另一个group，所以我们需要仔细的考虑Shard迁移的时候的行为，并避免出现不一致的情况。

项目是用Go编写的，机器之间的RPC是模拟的，模拟网络时延和分区的情况，并没有放到多台机器上去尝试。这个项目也是我独立完成的。但是只是一个learning project，对于真正生产中的情况还差的很多，所以还需要去研究一些KV的开源实现

代码以及具体的设计思路可以在github中找到，[链接](https://github.com/ysj1173886760/6.824_21)

## PyToy

背景是学校里开了一门叫智能计算系统的课程。主要讲了目前的深度学习训练框架的结构，以及下层硬件的一些设计。课程中有一些实验，包括去实现一些常用的算子，比如卷积，池化，并通过一些技术去优化他们的速度。以及去修改tensorflow添加新的算子。我在课程结束后感觉自己还是对深度学习框架并没有一个整体的理解。所以自己就尝试实现了PyToy这个深度学习框架。

我是用Python写的，由于我在这个项目上投入的时间不多，并且在深度学习方向的知识也比较浅，所以这个框架提供的功能相当有限，只是实现了一些常见的算子，比如卷积，BN，ReLU，池化，Dropout，以及一些优化器和损失函数等。我在里面用上了之前课程中用到的通过img2col优化卷积和池化的速度

由于计算图实际上就是一个DAG在不断的前后传播数据，所以我又根据拓扑的结构去尝试优化计算时候的内存开销。并基于ParameterServer的形式实现了分布式训练。每一次batch可以由多个worker计算，最后累加梯度并平均。

在项目中我也给出了一些具体的用例来演示如何使用这个框架。目前我也在学习GNN计算框架，图计算方向相关的知识，希望能构建出一个更加强大的系统。

代码可以在github中找到，[链接](https://github.com/ysj1173886760/PyToy)

## Bustub

Bustub是CMU15445的数据库作业，老师给提供了大体的框架，而我们则负责实现缓冲区管理，索引，执行算子以及并发控制。

这个项目是用C++写的，项目的一个难点就是去实现并发的B+树来做索引，同样是要考虑很多的细节情况。以及多个线程同时修改B+树的时候的处理。

受到这个项目的启发，我也想从头写一个完整的数据库，以此来加深自己对数据库整体系统的理解

通过这个项目让我对数据库管理系统有了一个比较清晰的认识，同时也打开了我在系统方向上的大门，让我对系统方向产生了浓厚的兴趣。

代码可以在github中找到，[链接](https://github.com/ysj1173886760/db_project)

# Backend Task

## Implementation

由于之前我对于网络服务器这方向了解的不是很多，只是初步涉及过socket编程。这次的任务对我来说还是有一定的挑战的。

最开始我的想法是用一些现成的http库来快速构建一个http服务器，然后再逐渐处理各种谓词逻辑

然而在经过了半天左右的尝试后，我发现由于我们的value是没有限制的，并且operator也有一些特殊的字符，导致我们的查询并不能很好的被现有的http库所支持并解析。所以我就打算从socket开始重头解析这些请求

经过了一段时间的尝试，以及对于请求的简化解析后，我成功的把GET请求后的query string读到了服务器中。然后下一个问题就是去读CSV文件了。解析的过程中我想到如果CSV内的条目有comma怎么办，于是就搜集了相关的资料，并找到了CSV文件的处理措施，通过双引号进行处理。我在stackoverflow中找到了一个基于状态机的解析方法，尝试之后发现效果不错，于是就打算用他的方法来读CSV。

之后便是对于predicate的解析，解析成功后就对每一行去尝试应用这些predicate，并把有效的行加入到结果中

在浏览器中以及cl中用curl测试的结果还不错，都可以返回预期的结果。

然后我又实现了一个http客户端，去发送假的http请求给服务器，并测试结果。我自己构造了若干种情况的请求，并给出了对应的正确返回结果。然后通过服务器的返回对比来测试服务器的稳定性

之后就是不断测试，修复一些小bug了过程了。

## Design

最开始的设计就是服务器的主线程去接受请求，然后创建新的线程去处理对应的请求。之后我考虑到如果大量的用户的情况下可能会导致服务器端有大量的线程，从而导致资源的浪费。所以就在初始化的时候去创建若干个worker，以及一个多线程的等待队列，服务器在接受到请求后就会把对应的文件描述符push到队列中，worker就可以在队列中取，处理请求并返回响应。

读取CSV文件中我做了一定的简化，我的假设是CSV的数据能够存到内存中，从而简化了一些地方的处理。这里其实也可以让操作系统帮我们缓存磁盘页，我们每次从磁盘中读取。但是这样的话我们需要每次都重新parse一遍CSV文件。

谓词的关系方面，由于我们没有制定优先级，所以我就把谓词处理成析取范式的形式，即(p1 and p2) or (p3 and p4) or (pxx and pyy)。在代码中的体现就是parse出来的谓词会是一个二维数组的形式，第一维就是用or连接，第二维则是用and来连接。

有一个我没有处理的点是这个谓词`C1 == "Test" and * $= "Prod" and * != "Hidden"`，因为我不太清楚\*的含义是什么，如果表示的是列名的话，我的处理是不合法的，因为列名中不含有\*，而如果表示的是all column的话，我的代码中对应的情况是不给出名字。在后面的测试环节也有提到。

特殊符号的处理，对于"来说，则是通过\"来进行转义，而\本身则是通过两个\来表达。而对于#来说，则是用%23来表示，否则浏览器不会把对应的字符串发过来

## Test

在client.cpp中我给出了一些测试的用例

比如`c1 $= "ABC" or c3 &= "\"\""`则是在测试包含双引号的请求，以及忽略大小写的情况

比如`c2 == "\"abc,cba\""`则是在测试数据中包含comma的情况，主要是在测试CSV的读

以及`c1 != "qwe" and c2 == "qwe" or c1 == "qwe" and c2 != "qwe"`，则是会根据上面的规则，转化成(c1 != "qwe" and c2 == "qwe") or (c1 == "qwe" and c2 != "qwe")。即在测试不等号以及谓词的关系

对于无效请求的情况，我也给出了测试，并会反馈对应的错误以提示用户。比如无效的column name，无效的operator，错误的谓词形式以及请求格式等

在client.cpp的request_table中我提供了多种不同的测试，并且有对应测试点的注释

之后我在client中进行了一定的并发访问测试。可以通过client.cpp中的workers和iteration来改变并发请求的个数，以及每个worker请求的次数

## Compile

编译环境是ubuntu20.04,需要链接pthread库

在目录下执行`make server`即可以编译服务器

`make client`则可以编译客户端

## Useage

`./server data.csv`即可以开启服务器，`data.csv`可以替换成其他数据的文件名。如果没有提供的话服务器会默认读取`data.csv`

`./client`则会开始进行并发的请求，从而测试服务器的正确性

浏览器中的使用：

比如输入
![20220319144145](https://picsheep.oss-cn-beijing.aliyuncs.com/pic/20220319144145.png)

则会返回
![20220319144201](https://picsheep.oss-cn-beijing.aliyuncs.com/pic/20220319144201.png)

## Lessons

首先就是再次复习了socket的使用，通过socket构建http服务器还是第一次。也从中了解到了一些服务器构建时候要考虑的东西。同时感觉也发现了一个不错的新领域，去构建高性能的服务器，最大化的利用网络和IO资源来构建一个强壮的服务器也是一个很有意思的事情。我之后会尝试深入的学习一下。

了解到了如何去parse CSV文件

做的时候也遇到了一些小bug，比如没有关闭文件描述符，则在一定数量的请求后服务器就会卡死。所以要保证资源的回收

实现的时候基本上都是按照最简单的情况去考虑的，很多地方还有优化的空间，比如支持更强大的谓词，我们可以通过用yacc和lex构建一个parser。以及查询时候的优化，比如提供索引，用字典树或者KMP去优化子串的查找。还可以提供更友好的接口，比如对错误情况下的提示，以及返回的数据的格式。还有IO复用，通过epoll等实现更高性能的服务器。

很关键的一点是认识到自己还有很多要学。